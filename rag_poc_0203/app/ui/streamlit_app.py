import streamlit as st
import requests
import os
import json
import uuid
from dotenv import load_dotenv

load_dotenv()

# Config
API_URL = "http://127.0.0.1:8000/chat"
EVAL_API_URL = "http://127.0.0.1:8000/eval/run"
COLLECTIONS_API_URL = "http://127.0.0.1:8000/rag/collections"
INGEST_API_URL = "http://127.0.0.1:8000/rag/ingest"
FEEDBACK_API_URL = "http://127.0.0.1:8000/chat/feedback"
LANGFUSE_HOST = os.getenv("LANGFUSE_HOST", "http://localhost:3000")
DATA_PATH = "data/golden_set.json"

st.set_page_config(page_title="AI ì„œë¹„ìŠ¤ ê´€ë¦¬ì", layout="wide")

st.title("ğŸ¤– AI ì„œë¹„ìŠ¤ ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ")

# Session State Initialization
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = str(uuid.uuid4())

# Tabs
tab_chat, tab_data, tab_eval = st.tabs(["ğŸ’¬ ì±„íŒ… & í…ŒìŠ¤íŠ¸", "ğŸ“Š ë°ì´í„°ì…‹ ê´€ë¦¬", "âœ… í‰ê°€ ì‹¤í–‰"])

# --- TAB 1: Chat ---
with tab_chat:
    # Sidebar: Control & Observability
    with st.sidebar:
        st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")
        
        st.divider()
        st.header("ğŸ•’ ëŒ€í™” ê¸°ë¡ (History)")
        
        @st.cache_data(ttl=10)
        def get_all_sessions():
            try:
                resp = requests.get("http://127.0.0.1:8000/chat/sessions")
                if resp.status_code == 200:
                    return resp.json()
                return []
            except:
                return []

        sessions = get_all_sessions()
        if sessions:
            # Create a dictionary for display
            session_options = {f"{s['summary'][:30]}... ({s['created_at'][:10]})": s['id'] for s in sessions}
            session_labels = list(session_options.keys())
            
            # Find current session index if it exists in history
            curr_idx = 0
            curr_sess_id = st.session_state.current_session_id
            for i, sid in enumerate(session_options.values()):
                if sid == curr_sess_id:
                    curr_idx = i
                    break
            
            selected_session_label = st.selectbox(
                "ê³¼ê±° ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°",
                options=session_labels,
                index=curr_idx
            )
            
            target_sid = session_options[selected_session_label]
            if target_sid != st.session_state.current_session_id:
                # Load selected session
                try:
                    msg_resp = requests.get(f"http://127.0.0.1:8000/chat/sessions/{target_sid}/messages")
                    if msg_resp.status_code == 200:
                        st.session_state.messages = msg_resp.json()
                        st.session_state.current_session_id = target_sid
                        st.session_state.pop("last_trace_id", None)
                        st.session_state.pop("last_retrieved_docs", None)
                        st.rerun()
                except Exception as e:
                    st.error(f"ëŒ€í™” ë¡œë“œ ì‹¤íŒ¨: {e}")

        if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘ (New Chat)", use_container_width=True):
            st.session_state.messages = []
            st.session_state.current_session_id = str(uuid.uuid4())
            st.session_state.pop("last_trace_id", None)
            st.session_state.pop("last_retrieved_docs", None)
            st.rerun()

        st.divider()

        agent_mode = st.radio(
            "ğŸ§© ì—ì´ì „íŠ¸ ëª¨ë“œ (Agent Mode)",
            options=["auto", "simple", "complex"],
            index=0,
            format_func=lambda x: {
                "auto": "ğŸ§  Automatic (ì§€ëŠ¥í˜• ë¼ìš°íŒ…)",
                "simple": "âš¡ï¸ Fast RAG (ê¸°ë³¸)",
                "complex": "ğŸ§© Advanced Agent (Planner/Critic)"
            }[x]
        )
        task_type = agent_mode
        
        st.divider()
        
        st.header("ğŸ“Š ê´€ì°° ê°€ëŠ¥ì„± (Observability)")
        st.info(f"ì„¸ì…˜ ID: `{st.session_state.current_session_id}`")
        if "last_trace_id" in st.session_state:
            trace_id = st.session_state["last_trace_id"]
            st.success(f"Trace ID: `{trace_id}`")
            # Link to generic Langfuse (user can adjust project-id)
            st.markdown(f"ğŸ”— [Langfuse ìƒì„¸ ë³´ê¸°]({LANGFUSE_HOST}/traces/{trace_id})")
        else:
            st.info("ì•„ì§ íŠ¸ë ˆì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        st.divider()
        st.header("ğŸ›ï¸ í”„ë¡¬í”„íŠ¸ ì˜¤ë²„ë¼ì´ë“œ")
        
        @st.cache_data(ttl=5)
        def get_all_prompt_names():
            try:
                import requests
                from requests.auth import HTTPBasicAuth
                resp = requests.get(
                    f"{LANGFUSE_HOST}/api/public/prompts",
                    auth=HTTPBasicAuth(os.getenv("LANGFUSE_PUBLIC_KEY"), os.getenv("LANGFUSE_SECRET_KEY"))
                )
                if resp.status_code == 200:
                    data = resp.json()
                    return sorted(list(set([item["name"] for item in data.get("data", [])])))
                return []
            except Exception as e:
                st.sidebar.error(f"Langfuse API ì—°ê²° ì˜¤ë¥˜: {e}")
                return []
        
        if st.button("ğŸ”„ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
            get_all_prompt_names.clear()
            st.rerun()
            
        available_prompts = get_all_prompt_names()

        st.divider()
        st.header("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ (Knowledge Base)")
        
        @st.cache_data(ttl=10)
        def get_collections():
            try:
                resp = requests.get(COLLECTIONS_API_URL)
                if resp.status_code == 200:
                    return resp.json().get("collections", [])
                return []
            except:
                return []

        available_collections = get_collections()
        if not available_collections:
             available_collections = ["knowledge_base"]

        selected_collection = st.selectbox(
            "ê²€ìƒ‰ ëŒ€ìƒ ì»¬ë ‰ì…˜ (Collection)", 
            options=available_collections
        )
        if st.button("ğŸ”„ ì»¬ë ‰ì…˜ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
            get_collections.clear()
            st.rerun()
            
        st.divider()
        st.header("ğŸ” ê²€ìƒ‰ ì„¤ì • (Retrieval)")
        top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Top-K)", min_value=1, max_value=10, value=3)
        search_type = st.radio("ê²€ìƒ‰ ëª¨ë¸ (Search Type)", options=["vector", "keyword", "hybrid", "graph"], horizontal=True)
        
        graph_mode = "hybrid"
        if search_type == "graph":
            graph_mode = st.selectbox("ê·¸ë˜í”„ ê²€ìƒ‰ ëª¨ë“œ (Graph Mode)", options=["local", "global", "hybrid", "naive"], index=2)
            st.info("ğŸ’¡ Graph SearchëŠ” ë°ì´í„° ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì •êµí•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

        use_reranker = st.checkbox("Reranking ì ìš© (ì •í™•ë„ í–¥ìƒ)", value=False)
        score_threshold = st.slider("ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (Score Threshold)", min_value=0.0, max_value=1.0, value=0.0, step=0.05)
        
        st.subheader("ğŸ¯ ë©”íƒ€ë°ì´í„° í•„í„°")
        filter_source = st.text_input("ì¶œì²˜(Source) í•„í„° (ì˜ˆ: manual.pdf)", value="")
        metadata_filters = {}
        if filter_source:
            metadata_filters["source"] = filter_source

        PROMPT_METADATA = {
            "system_default": {"label": "ğŸ¤– ì‹œìŠ¤í…œ í˜ë¥´ì†Œë‚˜", "desc": "AI ì—­í•  ì •ì˜", "vars": []},
            "rag_context": {"label": "ğŸ“„ Context ì£¼ì…", "desc": "ë¬¸ë§¥ ì „ë‹¬ í˜•ì‹", "vars": ["{retrieved_context}"]},
            "task_rag_qa": {"label": "â“ ë‹µë³€ ì‘ì„± ì§€ì¹¨", "desc": "êµ¬ì²´ì  ì§€ì‹œì‚¬í•­", "vars": ["{user_query}"]},
            "agent_planner": {"label": "ğŸ“… ê³„íš ìˆ˜ë¦½", "desc": "í•˜ìœ„ ì‘ì—… ë¶„í•  ë…¼ë¦¬", "vars": ["{user_query}"]},
            "agent_critic": {"label": "ğŸ§ ë¹„í‰ê°€", "desc": "ì‚¬ì‹¤ ê²€ì¦ ë…¼ë¦¬", "vars": ["{context}", "{answer}"]}
        }
        
        prompt_map = {}
        for key, meta in PROMPT_METADATA.items():
            options = sorted(list(set([key] + available_prompts)))
            idx = options.index(key) if key in options else 0
            st.markdown(f"**{meta['label']}**")
            selected_val = st.selectbox(f"Select Prompt for {key}", options=options, index=idx, key=f"sb_{key}", label_visibility="collapsed")
            if selected_val != key:
                prompt_map[key] = selected_val
            st.markdown("---")
            
    # Chat Interface
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì§€ì‹ ë² ì´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ìƒê° ì¤‘...")
            
            try:
                payload = {
                    "message": prompt, 
                    "session_id": st.session_state.current_session_id,
                    "task_type": task_type,
                    "prompt_map": prompt_map,
                    "collection_name": selected_collection,
                    "top_k": top_k,
                    "use_reranker": use_reranker,
                    "search_type": search_type,
                    "graph_mode": graph_mode,
                    "score_threshold": score_threshold,
                    "filters": metadata_filters
                }
                
                # Use streaming endpoint
                STREAM_API_URL = API_URL + "/stream"
                
                status_placeholder = st.empty()
                
                def stream_generator():
                    with requests.post(STREAM_API_URL, json=payload, stream=True) as r:
                        r.raise_for_status()
                        for line in r.iter_lines():
                            if line:
                                line_str = line.decode("utf-8")
                                if line_str.startswith("data: "):
                                    data = json.loads(line_str[6:])
                                    if data["event"] == "chunk":
                                        yield data["text"]
                                    elif data["event"] == "metadata":
                                        st.session_state["last_trace_id"] = data["trace_id"]
                                    elif data["event"] == "node":
                                        node_name = data["name"]
                                        if node_name == "rewrite_query":
                                            status_placeholder.info("ğŸ” **ì§ˆë¬¸ ìµœì í™” ì¤‘...** (Multi-Query Expansion)")
                                        elif node_name == "retrieve":
                                            status_placeholder.info("ğŸ“š **ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...** (Point-Cloud Search)")
                                        elif node_name == "grade_docs":
                                            status_placeholder.info("âš–ï¸ **ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± ì‹¬ì‚¬ ì¤‘...** (Self-Correction)")
                                        elif node_name == "web_search":
                                            status_placeholder.warning("ğŸŒ **ë‚´ë¶€ ì •ë³´ ë¶€ì¡±: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„ ì¤‘...** (CRAG Fallback)")
                                        elif node_name == "planner":
                                            status_placeholder.info("ğŸ“‹ **ìˆ˜í–‰ ê³„íš ìˆ˜ë¦½ ì¤‘...** (Advanced Reasoner)")
                                        elif node_name == "executor":
                                            status_placeholder.info("âš™ï¸ **ì‘ì—… ìˆ˜í–‰ ë° ë‹µë³€ ìƒì„± ì¤‘...**")
                                        elif node_name == "critic":
                                            status_placeholder.info("ğŸ§ **ë‹µë³€ ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€ ì¤‘...** (Refinement Loop)")
                                        elif node_name == "summarize":
                                            status_placeholder.info("ğŸ§  **ëŒ€í™” ìš”ì•½ ë° ê¸°ì–µ ì—…ë°ì´íŠ¸ ì¤‘...**")
                                        elif node_name == "generate":
                                            status_placeholder.empty()
                                    elif data["event"] == "done":
                                        st.session_state["last_retrieved_docs"] = data.get("retrieved_docs", [])
                                        status_placeholder.empty()

                answer = message_placeholder.write_stream(stream_generator())
                
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.rerun() 
            except Exception as e:
                message_placeholder.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # Trace & Feedback & Retrieval Inspector
    if "last_trace_id" in st.session_state and st.session_state.messages:
        curr_trace_id = st.session_state["last_trace_id"]
        
        st.divider()
        with st.expander("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ì¸ìŠ¤í™í„° (Retrieval Inspector)", expanded=False):
            st.info("ë°©ê¸ˆ ì „ ì§ˆë¬¸ì— ì‚¬ìš©ëœ ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
            
            docs = st.session_state.get("last_retrieved_docs", [])
            if docs:
                for i, d in enumerate(docs):
                    st.markdown(f"**[{i+1}] {d['source']}** (ìœ ì‚¬ë„: `{d['score']:.4f}`)")
                    st.text_area(f"ë‚´ìš© {i+1}", d['content'], height=100, key=f"doc_{i}")
            else:
                st.warning("ì¶”ì¶œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. (Self-RAGì— ì˜í•´ ê±°ì ˆë˜ì—ˆê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
            
            st.markdown(f"ğŸ”— [Langfuseì—ì„œ íŠ¸ë ˆì´ìŠ¤ ìì„¸íˆ ë³´ê¸°]({LANGFUSE_HOST}/project/project-123/traces/{curr_trace_id})")

        st.subheader("ğŸ“¬ ë‹µë³€ í‰ê°€ ë° ë¶„ì„")
        c1, c2, c3 = st.columns([1, 1, 3])
        with c1:
            if st.button("ğŸ‘ ì¢‹ì•„ìš”", key="btn_thumbs_up"):
                requests.post(FEEDBACK_API_URL, json={"trace_id": curr_trace_id, "score": 1, "name": "user-thumb"})
                st.toast("í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        with c2:
            if st.button("ğŸ‘ ì‹«ì–´ìš”", key="btn_thumbs_down"):
                requests.post(FEEDBACK_API_URL, json={"trace_id": curr_trace_id, "score": 0, "name": "user-thumb"})
                st.toast("í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        with c3:
             st.markdown(f"ğŸ”— [Langfuse ìƒì„¸ ë¶„ì„]({LANGFUSE_HOST}/project/project-123/traces/{curr_trace_id})")

# --- TAB 2: Ingest ---
with tab_data:
    st.header("ğŸ“¥ ë°ì´í„° ì ì¬ (Ingest)")
    with st.expander("ë°ì´í„° ì ì¬ íŒ¨ë„", expanded=False):
        uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "txt", "md", "json", "csv", "py"])
        target_collection = st.text_input("ì»¬ë ‰ì…˜ ì´ë¦„", value="knowledge_base")
        ingest_preset = st.selectbox("ì²­í‚¹ í”„ë¦¬ì…‹", options=["general", "legal", "code", "granular"])
        
        c1, c2 = st.columns(2)
        with c1:
            chunk_size = st.slider("ì²­í¬ í¬ê¸°", 100, 4000, 1000, 100)
        with c2:
            overlap_percent = st.slider("ì˜¤ë²„ë© (%)", 0, 50, 10, 5)
            chunk_overlap = int(chunk_size * (overlap_percent / 100))
            st.caption(f"ì‹¤ì œ ì˜¤ë²„ë©: {chunk_overlap} ì")

        if st.button("ğŸš€ ì‹¤í–‰"):
            if uploaded_file:
                with st.spinner("ì ì¬ ì¤‘..."):
                    try:
                        file_content = ""
                        if uploaded_file.name.lower().endswith('.pdf'):
                            import tempfile, pdf4llm
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                                tmp.write(uploaded_file.getvalue())
                                tmp_path = tmp.name
                            file_content = pdf4llm.to_markdown(tmp_path)
                            os.remove(tmp_path)
                        else:
                            file_content = uploaded_file.getvalue().decode("utf-8")
                        
                        payload = {
                            "text": file_content,
                            "collection_name": target_collection,
                            "filename": uploaded_file.name,
                            "chunk_size": chunk_size,
                            "chunk_overlap": chunk_overlap,
                            "preset": ingest_preset
                        }
                        resp = requests.post(INGEST_API_URL, json=payload)
                        if resp.status_code == 200:
                            st.success(f"ì ì¬ ì™„ë£Œ! {resp.json().get('message')}")
                        else:
                            st.error(f"ì ì¬ ì‹¤íŒ¨: {resp.text}")
                    except Exception as e:
                        st.error(f"ì ì¬ ì˜¤ë¥˜: {e}")

# --- TAB 3: Evaluation ---
with tab_eval:
    st.header("í‰ê°€ ë°ì´í„°ì…‹ ê´€ë¦¬")
    try:
        with open(DATA_PATH, "r") as f:
            current_data = json.load(f)
        updated_data = st.data_editor(current_data, num_rows="dynamic")
        if st.button("ğŸ’¾ ì €ì¥"):
            with open(DATA_PATH, "w") as f:
                json.dump(updated_data, f, indent=4)
            st.success("ë¡œì»¬ ì €ì¥ ì™„ë£Œ!")
    except Exception as e:
        st.error(f"ë°ì´í„°ì…‹ ë¡œë“œ ì˜¤ë¥˜: {e}")

    st.divider()
    if st.button("ğŸš€ ì „ì²´ í‰ê°€ ì‹œì‘"):
        with st.spinner("ì§„í–‰ ì¤‘..."):
            try:
                resp = requests.post(EVAL_API_URL)
                st.success(f"ìš”ì²­ ì„±ê³µ: {resp.json().get('message')}")
            except Exception as e:
                st.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
